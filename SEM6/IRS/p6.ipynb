{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ec71f5e",
   "metadata": {},
   "source": [
    "# Name: Devasy Patel\n",
    "## Roll No: 20BCE057\n",
    "# Practical 6: Implement a program for document classification using Naive Bayes and Bernoulli. Compare the performance of both algorithms using suitable accuracy parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e7baef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chinese  beijing  shanghai  macao  tokyo  japan\n",
      "0        1        1         0      0      0      0\n",
      "1        1        0         1      0      0      0\n",
      "2        1        0         0      1      0      0\n",
      "3        1        0         0      0      1      1\n",
      "P(chinese|c) : 0.7500 \t P(chinese|~c) : 0.2500\n",
      "P(beijing|c) : 0.1500 \t P(beijing|~c) : 0.0833\n",
      "P(shanghai|c) : 0.0900 \t P(shanghai|~c) : 0.0556\n",
      "P(macao|c) : 0.0540 \t P(macao|~c) : 0.0370\n",
      "P(tokyo|c) : 0.0324 \t P(tokyo|~c) : 0.0247\n",
      "P(japan|c) : 0.0259 \t P(japan|~c) : 0.0082\n",
      "\n",
      "P(c|Q) : 0.021\n",
      "\n",
      "P(~c|Q) : 0.003\n",
      "Given Query document will be classified as Answer : YES \n"
     ]
    }
   ],
   "source": [
    "#        Methodology followed : \n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "n = 4\n",
    "\n",
    "def count_terms(docs,temp,i):\n",
    "    temp = temp.split(\"\\n\")\n",
    "    pred = temp[1]\n",
    "    temp = word_tokenize(temp[0])\n",
    "    for word in temp:\n",
    "        if word.lower() not in docs.columns:\n",
    "            docs[word.lower()]=[0]*(n)\n",
    "        docs[word.lower()][i-1]=1\n",
    "    if(pred.lower()==\"yes\"):\n",
    "        docs[\"c=china\"][i-1]=1\n",
    "    else:\n",
    "        docs[\"c=china\"][i-1]=0\n",
    "    return docs\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    docs = []\n",
    "    docs = pd.DataFrame([])\n",
    "    docs[\"c=china\"]=[0]*n\n",
    "    total_words = 0\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        with open(\"U\"+str(i)+\".txt\") as fd:\n",
    "            temp = fd.read()\n",
    "            docs = count_terms(docs,temp,i)\n",
    "\n",
    "    YES_cnt  = np.sum(docs[\"c=china\"])\n",
    "    NO_cnt = n - YES_cnt\n",
    "    p_yes = YES_cnt/(YES_cnt+NO_cnt)\n",
    "    p_no = 1 - p_yes\n",
    "    ans_list = docs[\"c=china\"]\n",
    "    print(docs.iloc[:,1:])\n",
    "    query = input(\"\\n\\nEnter Query : \").split()\n",
    "    for word in docs.columns:\n",
    "        if(word==\"c=china\"):\n",
    "            continue\n",
    "        temp_yes = ((docs[word].dot(ans_list) + 1 )/(YES_cnt+2))\n",
    "        temp_no = ((docs[word].dot(~ans_list + 2) + 1 )/(NO_cnt+2))\n",
    "        print(\"P({0:}|c) : {1:.4f} \\t P({0:}|~c) : {2:.4f}\".format(word,p_yes,p_no))\n",
    "        if word in query:\n",
    "            p_yes *= temp_yes\n",
    "            p_no *= temp_no\n",
    "        else:        \n",
    "            p_yes *= (1-temp_yes) \n",
    "            p_no *= (1-temp_no)\n",
    "    \n",
    "    \n",
    "    print(\"\\nP(c|Q) : {:.3f}\".format(p_yes))\n",
    "    print(\"\\nP(~c|Q) : {:.3f}\".format(p_no))\n",
    "    if(p_yes>=p_no):\n",
    "        print(\"Given Query document will be classified as Answer : YES \")\n",
    "    else:\n",
    "        print(\"Given Query document will be classified as Answer : NO \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0689ab",
   "metadata": {},
   "source": [
    "Aim : Classify Given Documents using Bernoullie classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2b6e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chinese  beijing  shanghai  macao  tokyo  japan\n",
      "0        2        1         0      0      0      0\n",
      "1        2        0         1      0      0      0\n",
      "2        1        0         0      1      0      0\n",
      "3        1        0         0      0      1      1\n",
      "\n",
      "\n",
      "Enter Query : chinese chinese chinese tokyo japan\n",
      "P(chinese|c) : 0.750 \t P(chinese|~c) : 0.250\n",
      "P(beijing|c) : 0.750 \t P(beijing|~c) : 0.250\n",
      "P(shanghai|c) : 0.750 \t P(shanghai|~c) : 0.250\n",
      "P(macao|c) : 0.750 \t P(macao|~c) : 0.250\n",
      "P(tokyo|c) : 0.750 \t P(tokyo|~c) : 0.250\n",
      "P(japan|c) : 0.750 \t P(japan|~c) : 0.250\n",
      "\n",
      "P(c|Q) : 0.0003\n",
      "\n",
      "P(~c|Q) : 0.0001\n",
      "Given Query document will be classified as Answer : YES \n"
     ]
    }
   ],
   "source": [
    "#        Methodology followed : \n",
    "\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import warnings\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "n = 4\n",
    "\n",
    "def count_terms(docs,temp,i):\n",
    "    temp = temp.split(\"\\n\")\n",
    "    pred = temp[1]\n",
    "    temp = word_tokenize(temp[0])\n",
    "    for word in temp:\n",
    "        if word.lower() not in docs.columns:\n",
    "            docs[word.lower()]=[0]*(n)\n",
    "        docs[word.lower()][i-1]+=1\n",
    "        docs[\"total\"][i-1]+=1\n",
    "    if(pred.lower()==\"yes\"):\n",
    "        docs[\"c=china\"][i-1]=1\n",
    "    else:\n",
    "        docs[\"c=china\"][i-1]=0\n",
    "    return docs\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    docs = []\n",
    "    docs = pd.DataFrame([])\n",
    "    docs[\"c=china\"]=[0]*n\n",
    "    docs[\"total\"]=[0]*n\n",
    "    total_words = 0\n",
    "    \n",
    "    for i in range(1,n+1):\n",
    "        with open(\"U\"+str(i)+\".txt\") as fd:\n",
    "            temp = fd.read()\n",
    "            docs = count_terms(docs,temp,i)\n",
    "    \n",
    "    diff_word_cnt = docs.count(axis=1)[0] - 2\n",
    "\n",
    "    YES_cnt  = np.sum(docs[\"c=china\"])\n",
    "    NO_cnt = n - YES_cnt\n",
    "\n",
    "\n",
    "    p_yes = YES_cnt/(YES_cnt+NO_cnt)\n",
    "    p_no = 1 - p_yes\n",
    "\n",
    "    p_words = dict()\n",
    "\n",
    "\n",
    "    ans_list = docs[\"c=china\"]\n",
    "    print(docs.iloc[:,2:])\n",
    "\n",
    "    \n",
    "\n",
    "    query = input(\"\\n\\nEnter Query : \").split()\n",
    "    for word in docs.columns:\n",
    "        if(word==\"c=china\" or word==\"total\"):\n",
    "            continue\n",
    "        temp_yes = ((docs[word].dot(ans_list) + 1 )/(docs[\"total\"].dot(ans_list) + diff_word_cnt))\n",
    "        temp_no = ((docs[word].dot(~ans_list + 2) + 1 )/(docs[\"total\"].dot(~ans_list + 2) + diff_word_cnt))\n",
    "        p_words[word] = [temp_yes,temp_no]\n",
    "        print(\"P({0:}|c) : {1:.3f} \\t P({0:}|~c) : {2:.3f}\".format(word,p_yes,p_no))\n",
    "\n",
    "\n",
    "    for word in query:\n",
    "        p_yes*=p_words[word][0]\n",
    "        p_no*=p_words[word][1]\n",
    "\n",
    "        \n",
    "    print(\"\\nP(c|Q) : {:.4f}\".format(p_yes))\n",
    "    print(\"\\nP(~c|Q) : {:.4f}\".format(p_no))\n",
    "    if(p_yes>=p_no):\n",
    "        print(\"Given Query document will be classified as Answer : YES \")\n",
    "    else:\n",
    "        print(\"Given Query document will be classified as Answer : NO \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "86ae5f978ea280640f3fb52d952e96eb04ff76ade804b32eac05c9293156856f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
