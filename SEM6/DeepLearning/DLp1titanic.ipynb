{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic dataset on kaggle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we have to deal with missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age has 177 missing values\n",
    "# embarked has 2 missing values\n",
    "\n",
    "# we can fill the missing values of age with mean of age\n",
    "df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    " \n",
    "# we can fill the missing values of embarked with mode of embarked\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0],inplace=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to deal with categorical values\n",
    " \n",
    "# we can use one hot encoding for embarked\n",
    "df = pd.get_dummies(df,columns=['Embarked'],drop_first=True)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Owner\\Desktop\\SEM 5\\DL\\DLp1titanic.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/SEM%205/DL/DLp1titanic.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# now we have to deal with categorical values in age and Pclass\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/SEM%205/DL/DLp1titanic.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/SEM%205/DL/DLp1titanic.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# we can use label encoding for Pclass\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/SEM%205/DL/DLp1titanic.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/SEM%205/DL/DLp1titanic.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m le \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Owner/Desktop/SEM%205/DL/DLp1titanic.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mPclass\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mfit_transform(df[\u001b[39m'\u001b[39m\u001b[39mPclass\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_label\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_label\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiLabelBinarizer\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_discretization\u001b[39;00m \u001b[39mimport\u001b[39;00m KBinsDiscretizer\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_polynomial\u001b[39;00m \u001b[39mimport\u001b[39;00m PolynomialFeatures\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_polynomial\u001b[39;00m \u001b[39mimport\u001b[39;00m SplineTransformer\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# now we have to deal with categorical values in age and Pclass\n",
    "\n",
    "# we can use label encoding for Pclass\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Pclass'] = le.fit_transform(df['Pclass'])\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.699118\n",
       "std       13.002015\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       29.699118\n",
       "75%       35.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now for age we can use binning\n",
    "df['Age'].describe()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can divide age into 5 bins\n",
    "df['Age'] = pd.cut(df['Age'],bins=[0,20,40,60,80,100],labels=['0-20','20-40','40-60','60-80','80-100'])\n",
    "df = pd.get_dummies(df,columns=['Age'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_0-20</th>\n",
       "      <th>Age_20-40</th>\n",
       "      <th>Age_40-60</th>\n",
       "      <th>Age_60-80</th>\n",
       "      <th>Age_80-100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex  SibSp  Parch     Fare  Embarked_Q  Embarked_S  \\\n",
       "0           0       2    male      1      0   7.2500           0           1   \n",
       "1           1       0  female      1      0  71.2833           0           0   \n",
       "2           1       2  female      0      0   7.9250           0           1   \n",
       "3           1       0  female      1      0  53.1000           0           1   \n",
       "4           0       2    male      0      0   8.0500           0           1   \n",
       "..        ...     ...     ...    ...    ...      ...         ...         ...   \n",
       "886         0       1    male      0      0  13.0000           0           1   \n",
       "887         1       0  female      0      0  30.0000           0           1   \n",
       "888         0       2  female      1      2  23.4500           0           1   \n",
       "889         1       0    male      0      0  30.0000           0           0   \n",
       "890         0       2    male      0      0   7.7500           1           0   \n",
       "\n",
       "     Age_0-20  Age_20-40  Age_40-60  Age_60-80  Age_80-100  \n",
       "0           0          1          0          0           0  \n",
       "1           0          1          0          0           0  \n",
       "2           0          1          0          0           0  \n",
       "3           0          1          0          0           0  \n",
       "4           0          1          0          0           0  \n",
       "..        ...        ...        ...        ...         ...  \n",
       "886         0          1          0          0           0  \n",
       "887         1          0          0          0           0  \n",
       "888         0          1          0          0           0  \n",
       "889         0          1          0          0           0  \n",
       "890         0          1          0          0           0  \n",
       "\n",
       "[891 rows x 13 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Age_0-20</th>\n",
       "      <th>Age_20-40</th>\n",
       "      <th>Age_40-60</th>\n",
       "      <th>Age_60-80</th>\n",
       "      <th>Age_80-100</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  SibSp  Parch     Fare  Embarked_Q  Embarked_S  \\\n",
       "0           0       2      1      0   7.2500           0           1   \n",
       "1           1       0      1      0  71.2833           0           0   \n",
       "2           1       2      0      0   7.9250           0           1   \n",
       "3           1       0      1      0  53.1000           0           1   \n",
       "4           0       2      0      0   8.0500           0           1   \n",
       "..        ...     ...    ...    ...      ...         ...         ...   \n",
       "886         0       1      0      0  13.0000           0           1   \n",
       "887         1       0      0      0  30.0000           0           1   \n",
       "888         0       2      1      2  23.4500           0           1   \n",
       "889         1       0      0      0  30.0000           0           0   \n",
       "890         0       2      0      0   7.7500           1           0   \n",
       "\n",
       "     Age_0-20  Age_20-40  Age_40-60  Age_60-80  Age_80-100  Sex_female  \\\n",
       "0           0          1          0          0           0           0   \n",
       "1           0          1          0          0           0           1   \n",
       "2           0          1          0          0           0           1   \n",
       "3           0          1          0          0           0           1   \n",
       "4           0          1          0          0           0           0   \n",
       "..        ...        ...        ...        ...         ...         ...   \n",
       "886         0          1          0          0           0           0   \n",
       "887         1          0          0          0           0           1   \n",
       "888         0          1          0          0           0           1   \n",
       "889         0          1          0          0           0           0   \n",
       "890         0          1          0          0           0           0   \n",
       "\n",
       "     Sex_male  \n",
       "0           1  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "..        ...  \n",
       "886         1  \n",
       "887         0  \n",
       "888         0  \n",
       "889         1  \n",
       "890         1  \n",
       "\n",
       "[891 rows x 14 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  for sex we can use label encoding\n",
    "df1 = pd.get_dummies(df,columns=['Sex'])\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now preprocessing is done\n",
    "# now we can split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = df1['Survived']\n",
    "X = df1.drop('Survived',axis=1)\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    " \n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "# ypred = model.predict(X_test)\n",
    "# model.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.8058676654182271 0.0384237537990322\n",
      "AdaBoostClassifier 0.7980149812734083 0.027670806386333235\n",
      "GradientBoostingClassifier 0.8227215980024969 0.0378999569758008\n",
      "ExtraTreesClassifier 0.8047191011235955 0.040229740443601864\n",
      "DecisionTreeClassifier 0.77896379525593 0.045115542725649105\n",
      "SVC 0.6746317103620475 0.04242379481999435\n",
      "KNeighborsClassifier 0.7575905118601748 0.03952489307202209\n",
      "GaussianNB 0.7867665418227215 0.03006536665226887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.7890636704119849 0.02991606882050778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;RandomForestClassifier&#x27;,\n",
       "                              RandomForestClassifier()),\n",
       "                             (&#x27;AdaBoostClassifier&#x27;, AdaBoostClassifier()),\n",
       "                             (&#x27;GradientBoostingClassifier&#x27;,\n",
       "                              GradientBoostingClassifier()),\n",
       "                             (&#x27;ExtraTreesClassifier&#x27;, ExtraTreesClassifier()),\n",
       "                             (&#x27;DecisionTreeClassifier&#x27;,\n",
       "                              DecisionTreeClassifier()),\n",
       "                             (&#x27;SVC&#x27;, SVC()),\n",
       "                             (&#x27;KNeighborsClassifier&#x27;, KNeighborsClassifier()),\n",
       "                             (&#x27;GaussianNB&#x27;, GaussianNB()),\n",
       "                             (&#x27;LogisticRegression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;RandomForestClassifier&#x27;,\n",
       "                              RandomForestClassifier()),\n",
       "                             (&#x27;AdaBoostClassifier&#x27;, AdaBoostClassifier()),\n",
       "                             (&#x27;GradientBoostingClassifier&#x27;,\n",
       "                              GradientBoostingClassifier()),\n",
       "                             (&#x27;ExtraTreesClassifier&#x27;, ExtraTreesClassifier()),\n",
       "                             (&#x27;DecisionTreeClassifier&#x27;,\n",
       "                              DecisionTreeClassifier()),\n",
       "                             (&#x27;SVC&#x27;, SVC()),\n",
       "                             (&#x27;KNeighborsClassifier&#x27;, KNeighborsClassifier()),\n",
       "                             (&#x27;GaussianNB&#x27;, GaussianNB()),\n",
       "                             (&#x27;LogisticRegression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RandomForestClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>AdaBoostClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GradientBoostingClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ExtraTreesClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DecisionTreeClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>KNeighborsClassifier</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GaussianNB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('RandomForestClassifier',\n",
       "                              RandomForestClassifier()),\n",
       "                             ('AdaBoostClassifier', AdaBoostClassifier()),\n",
       "                             ('GradientBoostingClassifier',\n",
       "                              GradientBoostingClassifier()),\n",
       "                             ('ExtraTreesClassifier', ExtraTreesClassifier()),\n",
       "                             ('DecisionTreeClassifier',\n",
       "                              DecisionTreeClassifier()),\n",
       "                             ('SVC', SVC()),\n",
       "                             ('KNeighborsClassifier', KNeighborsClassifier()),\n",
       "                             ('GaussianNB', GaussianNB()),\n",
       "                             ('LogisticRegression', LogisticRegression())])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try ensemble methods\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "ensemble = []\n",
    "ensemble.append(('RandomForestClassifier',RandomForestClassifier()))\n",
    "ensemble.append(('AdaBoostClassifier',AdaBoostClassifier()))\n",
    "ensemble.append(('GradientBoostingClassifier',GradientBoostingClassifier()))\n",
    "ensemble.append(('ExtraTreesClassifier',ExtraTreesClassifier()))\n",
    "ensemble.append(('DecisionTreeClassifier',DecisionTreeClassifier()))\n",
    "ensemble.append(('SVC',SVC()))\n",
    "ensemble.append(('KNeighborsClassifier',KNeighborsClassifier()))\n",
    "ensemble.append(('GaussianNB',GaussianNB()))\n",
    "ensemble.append(('LogisticRegression',LogisticRegression()))\n",
    "    \n",
    "for name,model in ensemble:\n",
    "    kfold = KFold(n_splits=10)\n",
    "    cv_results = cross_val_score(model,X,y,cv=kfold,scoring='accuracy')\n",
    "    print(name,cv_results.mean(),cv_results.std())\n",
    "    \n",
    "ensemble = VotingClassifier(ensemble)\n",
    "ensemble.fit(X,y)\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass       0\n",
       "Sex          0\n",
       "Age         86\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Fare         1\n",
       "Embarked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_csv('test.csv')\n",
    "testdf.drop(['PassengerId','Name','Ticket','Cabin'],axis=1,inplace=True)\n",
    "testdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf['Age'].fillna(testdf['Age'].mean(),inplace=True)\n",
    "testdf['Fare'].fillna(testdf['Fare'].mean(),inplace=True)\n",
    "# testdf['Embarked'].fillna(testdf['Embarked'].mode()[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.get_dummies(testdf,columns=['Embarked'],drop_first=True)\n",
    "testdf['Pclass'] = le.fit_transform(testdf['Pclass'])\n",
    "testdf['Age'] = pd.cut(testdf['Age'],bins=[0,20,40,60,80,100],labels=['0-20','20-40','40-60','60-80','80-100'])\n",
    "testdf = pd.get_dummies(testdf,columns=['Age'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = pd.get_dummies(testdf, columns=['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.56261796e-02],\n",
       "       [5.00025392e-01],\n",
       "       [9.77806076e-02],\n",
       "       [9.82059389e-02],\n",
       "       [3.42348665e-01],\n",
       "       [1.41326994e-01],\n",
       "       [7.55895793e-01],\n",
       "       [1.56629607e-01],\n",
       "       [5.13314605e-01],\n",
       "       [3.07372063e-02],\n",
       "       [1.00919165e-01],\n",
       "       [2.01009974e-01],\n",
       "       [9.10319388e-01],\n",
       "       [1.24107242e-01],\n",
       "       [8.62046957e-01],\n",
       "       [8.72092187e-01],\n",
       "       [1.40991718e-01],\n",
       "       [1.69417560e-01],\n",
       "       [4.76552367e-01],\n",
       "       [5.90633929e-01],\n",
       "       [1.91010416e-01],\n",
       "       [1.09187663e-01],\n",
       "       [9.48562324e-01],\n",
       "       [2.59193271e-01],\n",
       "       [2.29320139e-01],\n",
       "       [5.83277158e-02],\n",
       "       [9.36181903e-01],\n",
       "       [1.69417560e-01],\n",
       "       [1.98364884e-01],\n",
       "       [5.53087071e-02],\n",
       "       [9.17359963e-02],\n",
       "       [7.10526779e-02],\n",
       "       [4.89563257e-01],\n",
       "       [5.27878642e-01],\n",
       "       [3.34057927e-01],\n",
       "       [1.27049088e-01],\n",
       "       [4.68858987e-01],\n",
       "       [4.83698219e-01],\n",
       "       [9.66509655e-02],\n",
       "       [1.89425796e-01],\n",
       "       [1.82166532e-01],\n",
       "       [3.64998788e-01],\n",
       "       [8.53906348e-02],\n",
       "       [8.31954837e-01],\n",
       "       [8.68537545e-01],\n",
       "       [1.00814350e-01],\n",
       "       [2.25286558e-01],\n",
       "       [7.56238252e-02],\n",
       "       [8.36726010e-01],\n",
       "       [6.11333787e-01],\n",
       "       [2.44801253e-01],\n",
       "       [2.94753700e-01],\n",
       "       [7.15910316e-01],\n",
       "       [5.48620820e-01],\n",
       "       [2.98225135e-01],\n",
       "       [6.05470426e-02],\n",
       "       [1.00919165e-01],\n",
       "       [1.01805076e-01],\n",
       "       [5.70453554e-02],\n",
       "       [5.30661941e-01],\n",
       "       [1.24424219e-01],\n",
       "       [1.37745678e-01],\n",
       "       [1.23029321e-01],\n",
       "       [7.58638620e-01],\n",
       "       [2.82403734e-02],\n",
       "       [9.00089562e-01],\n",
       "       [6.34806991e-01],\n",
       "       [1.73067436e-01],\n",
       "       [3.90712649e-01],\n",
       "       [1.88254654e-01],\n",
       "       [7.59350955e-01],\n",
       "       [1.00919165e-01],\n",
       "       [4.65801716e-01],\n",
       "       [3.93356055e-01],\n",
       "       [6.92902684e-01],\n",
       "       [5.07337414e-02],\n",
       "       [1.00366868e-01],\n",
       "       [6.05325758e-01],\n",
       "       [1.34734765e-01],\n",
       "       [7.59350955e-01],\n",
       "       [3.83523077e-01],\n",
       "       [9.05167405e-03],\n",
       "       [2.01009974e-01],\n",
       "       [1.00919165e-01],\n",
       "       [1.28797233e-01],\n",
       "       [1.06821775e-01],\n",
       "       [7.62999654e-01],\n",
       "       [3.88931453e-01],\n",
       "       [7.59350955e-01],\n",
       "       [4.68004405e-01],\n",
       "       [3.40067863e-01],\n",
       "       [1.01353697e-01],\n",
       "       [9.25583243e-01],\n",
       "       [1.00366868e-01],\n",
       "       [3.98946583e-01],\n",
       "       [1.01278760e-01],\n",
       "       [7.02589512e-01],\n",
       "       [1.00814350e-01],\n",
       "       [3.80977720e-01],\n",
       "       [1.00366868e-01],\n",
       "       [8.85879934e-01],\n",
       "       [1.33019075e-01],\n",
       "       [7.56238252e-02],\n",
       "       [1.01353697e-01],\n",
       "       [9.16353643e-01],\n",
       "       [1.29039615e-01],\n",
       "       [7.56220520e-02],\n",
       "       [7.56238252e-02],\n",
       "       [9.81435776e-02],\n",
       "       [3.43599766e-01],\n",
       "       [1.64880320e-01],\n",
       "       [7.60181069e-01],\n",
       "       [9.56314981e-01],\n",
       "       [6.04567945e-01],\n",
       "       [2.58360922e-01],\n",
       "       [3.17218363e-01],\n",
       "       [1.71961263e-01],\n",
       "       [6.59606755e-01],\n",
       "       [2.53771305e-01],\n",
       "       [7.95687079e-01],\n",
       "       [8.66744995e-01],\n",
       "       [6.79667965e-02],\n",
       "       [9.44933593e-01],\n",
       "       [1.02964781e-01],\n",
       "       [7.56238252e-02],\n",
       "       [7.45604575e-01],\n",
       "       [1.01278760e-01],\n",
       "       [5.79370320e-01],\n",
       "       [9.90272611e-02],\n",
       "       [1.00366868e-01],\n",
       "       [1.00366868e-01],\n",
       "       [2.28401780e-01],\n",
       "       [3.33547562e-01],\n",
       "       [1.23141356e-01],\n",
       "       [8.56420100e-02],\n",
       "       [1.01068601e-01],\n",
       "       [1.69417560e-01],\n",
       "       [1.34734765e-01],\n",
       "       [4.68858987e-01],\n",
       "       [2.43149828e-02],\n",
       "       [8.12781751e-02],\n",
       "       [8.24475825e-01],\n",
       "       [3.18145216e-03],\n",
       "       [2.40626812e-01],\n",
       "       [2.00727358e-01],\n",
       "       [2.60227211e-02],\n",
       "       [3.01111490e-01],\n",
       "       [1.00366868e-01],\n",
       "       [3.64998788e-01],\n",
       "       [1.57847703e-01],\n",
       "       [9.16893303e-01],\n",
       "       [1.70018554e-01],\n",
       "       [8.85386541e-02],\n",
       "       [5.52264154e-01],\n",
       "       [3.64072509e-02],\n",
       "       [1.02167457e-01],\n",
       "       [6.44100368e-01],\n",
       "       [4.64071274e-01],\n",
       "       [2.00727358e-01],\n",
       "       [5.79267919e-01],\n",
       "       [7.58875310e-01],\n",
       "       [3.83523077e-01],\n",
       "       [8.38087976e-01],\n",
       "       [1.03623658e-01],\n",
       "       [9.90272611e-02],\n",
       "       [5.38321912e-01],\n",
       "       [1.76935226e-01],\n",
       "       [2.03658372e-01],\n",
       "       [9.53866243e-01],\n",
       "       [4.91389751e-01],\n",
       "       [1.02167457e-01],\n",
       "       [1.69417560e-01],\n",
       "       [5.70422560e-02],\n",
       "       [1.69421360e-01],\n",
       "       [2.92327553e-02],\n",
       "       [9.07926977e-01],\n",
       "       [9.29882348e-01],\n",
       "       [1.99609265e-01],\n",
       "       [8.17389131e-01],\n",
       "       [6.05564475e-01],\n",
       "       [1.34734765e-01],\n",
       "       [2.34063223e-01],\n",
       "       [9.37516868e-01],\n",
       "       [7.56238252e-02],\n",
       "       [5.80575705e-01],\n",
       "       [1.53655976e-01],\n",
       "       [8.95804882e-01],\n",
       "       [1.72459498e-01],\n",
       "       [3.00588761e-03],\n",
       "       [1.34734765e-01],\n",
       "       [1.33019075e-01],\n",
       "       [3.62958580e-01],\n",
       "       [2.92765975e-01],\n",
       "       [9.47549343e-02],\n",
       "       [3.91404510e-01],\n",
       "       [1.01068601e-01],\n",
       "       [1.06919229e-01],\n",
       "       [3.77778322e-01],\n",
       "       [1.26173288e-01],\n",
       "       [4.70388472e-01],\n",
       "       [8.72442424e-01],\n",
       "       [2.23876283e-01],\n",
       "       [2.25850753e-02],\n",
       "       [8.79337370e-01],\n",
       "       [1.26173288e-01],\n",
       "       [3.99787962e-01],\n",
       "       [7.59350955e-01],\n",
       "       [1.26173288e-01],\n",
       "       [9.53866243e-01],\n",
       "       [1.00919165e-01],\n",
       "       [1.29039615e-01],\n",
       "       [1.03491567e-01],\n",
       "       [2.13785931e-01],\n",
       "       [7.02294350e-01],\n",
       "       [9.95918810e-01],\n",
       "       [1.72855556e-01],\n",
       "       [7.62999654e-01],\n",
       "       [3.46534699e-02],\n",
       "       [4.49778050e-01],\n",
       "       [1.00366868e-01],\n",
       "       [7.79618680e-01],\n",
       "       [1.00366868e-01],\n",
       "       [7.89179802e-01],\n",
       "       [1.01278760e-01],\n",
       "       [8.99566531e-01],\n",
       "       [6.43344998e-01],\n",
       "       [1.01278760e-01],\n",
       "       [7.59350955e-01],\n",
       "       [7.72978142e-02],\n",
       "       [1.34734765e-01],\n",
       "       [2.33828723e-01],\n",
       "       [9.47786391e-01],\n",
       "       [8.70799348e-02],\n",
       "       [7.56508484e-02],\n",
       "       [2.96420008e-01],\n",
       "       [1.24024883e-01],\n",
       "       [7.47880191e-02],\n",
       "       [1.27004877e-01],\n",
       "       [8.10352802e-01],\n",
       "       [7.99836338e-01],\n",
       "       [8.99392426e-01],\n",
       "       [6.94663405e-01],\n",
       "       [5.99226914e-02],\n",
       "       [1.00948967e-01],\n",
       "       [1.12540670e-01],\n",
       "       [1.78485706e-01],\n",
       "       [9.00089562e-01],\n",
       "       [8.06341916e-02],\n",
       "       [7.95687079e-01],\n",
       "       [5.56381345e-01],\n",
       "       [8.66834044e-01],\n",
       "       [1.24705270e-01],\n",
       "       [1.47556975e-01],\n",
       "       [9.69949365e-02],\n",
       "       [9.66509655e-02],\n",
       "       [1.02167457e-01],\n",
       "       [7.56238252e-02],\n",
       "       [1.00366868e-01],\n",
       "       [8.38038027e-01],\n",
       "       [1.01353697e-01],\n",
       "       [5.76387197e-02],\n",
       "       [1.01068601e-01],\n",
       "       [8.38893652e-01],\n",
       "       [5.75373113e-01],\n",
       "       [2.74995387e-01],\n",
       "       [1.00919165e-01],\n",
       "       [1.07926817e-03],\n",
       "       [1.02167457e-01],\n",
       "       [4.68858987e-01],\n",
       "       [1.32892430e-01],\n",
       "       [1.32464647e-01],\n",
       "       [7.56238252e-02],\n",
       "       [8.79629672e-01],\n",
       "       [7.42745578e-01],\n",
       "       [1.69417560e-01],\n",
       "       [8.39162946e-01],\n",
       "       [1.26173288e-01],\n",
       "       [1.33019075e-01],\n",
       "       [1.17367551e-01],\n",
       "       [1.26173288e-01],\n",
       "       [4.83698219e-01],\n",
       "       [2.88270891e-01],\n",
       "       [7.59350955e-01],\n",
       "       [7.51249611e-01],\n",
       "       [7.10878909e-01],\n",
       "       [1.02964781e-01],\n",
       "       [1.02964781e-01],\n",
       "       [2.19192326e-01],\n",
       "       [1.69421360e-01],\n",
       "       [1.00366868e-01],\n",
       "       [3.37271959e-01],\n",
       "       [7.28365123e-01],\n",
       "       [1.69421360e-01],\n",
       "       [1.01599418e-01],\n",
       "       [9.66509655e-02],\n",
       "       [1.00919165e-01],\n",
       "       [8.96358669e-01],\n",
       "       [5.53087071e-02],\n",
       "       [3.19601983e-01],\n",
       "       [1.01068601e-01],\n",
       "       [1.01353697e-01],\n",
       "       [2.94832975e-01],\n",
       "       [9.18098837e-02],\n",
       "       [9.82059389e-02],\n",
       "       [7.59350955e-01],\n",
       "       [7.74551809e-01],\n",
       "       [8.66632164e-02],\n",
       "       [1.57748893e-01],\n",
       "       [8.78227204e-02],\n",
       "       [2.71018147e-01],\n",
       "       [1.32892430e-01],\n",
       "       [1.69417560e-01],\n",
       "       [1.02076776e-01],\n",
       "       [7.59350955e-01],\n",
       "       [6.95965767e-01],\n",
       "       [6.27897143e-01],\n",
       "       [6.61234856e-02],\n",
       "       [2.92858988e-01],\n",
       "       [1.01068601e-01],\n",
       "       [7.10526779e-02],\n",
       "       [1.01353697e-01],\n",
       "       [1.69421360e-01],\n",
       "       [1.34734765e-01],\n",
       "       [3.64998788e-01],\n",
       "       [6.75903499e-01],\n",
       "       [1.03491567e-01],\n",
       "       [8.17846656e-01],\n",
       "       [1.26301944e-01],\n",
       "       [1.33019075e-01],\n",
       "       [1.34734765e-01],\n",
       "       [7.20265627e-01],\n",
       "       [3.86960775e-01],\n",
       "       [1.69417560e-01],\n",
       "       [7.54411101e-01],\n",
       "       [1.00919165e-01],\n",
       "       [3.62958580e-01],\n",
       "       [1.34734765e-01],\n",
       "       [9.51294824e-02],\n",
       "       [2.75586367e-01],\n",
       "       [1.69421360e-01],\n",
       "       [2.92858988e-01],\n",
       "       [1.02061532e-01],\n",
       "       [7.84536730e-03],\n",
       "       [1.15722297e-02],\n",
       "       [7.37566948e-02],\n",
       "       [3.72750342e-01],\n",
       "       [1.34734765e-01],\n",
       "       [7.37887621e-01],\n",
       "       [1.37745678e-01],\n",
       "       [9.00089562e-01],\n",
       "       [8.38954091e-01],\n",
       "       [1.26173288e-01],\n",
       "       [2.13785931e-01],\n",
       "       [4.40598316e-02],\n",
       "       [7.23783672e-01],\n",
       "       [2.01009974e-01],\n",
       "       [7.86736369e-01],\n",
       "       [1.00978777e-01],\n",
       "       [7.56238252e-02],\n",
       "       [3.68718237e-01],\n",
       "       [1.35214743e-03],\n",
       "       [9.00189400e-01],\n",
       "       [9.00089562e-01],\n",
       "       [9.82059389e-02],\n",
       "       [9.45338845e-01],\n",
       "       [5.94698265e-02],\n",
       "       [1.06831580e-01],\n",
       "       [8.67025256e-01],\n",
       "       [8.46147895e-01],\n",
       "       [2.87362337e-01],\n",
       "       [9.29654390e-02],\n",
       "       [8.65232408e-01],\n",
       "       [1.61210803e-04],\n",
       "       [9.90272611e-02],\n",
       "       [8.14293921e-01],\n",
       "       [2.90471524e-01],\n",
       "       [7.88312018e-01],\n",
       "       [1.28730416e-01],\n",
       "       [1.57554105e-01],\n",
       "       [3.64072509e-02],\n",
       "       [7.56238252e-02],\n",
       "       [7.56508484e-02],\n",
       "       [6.44783437e-01],\n",
       "       [5.16517937e-01],\n",
       "       [1.33990824e-01],\n",
       "       [8.81793737e-01],\n",
       "       [1.01353697e-01],\n",
       "       [9.90272611e-02],\n",
       "       [7.56238252e-02],\n",
       "       [6.10481873e-02],\n",
       "       [1.96631655e-01],\n",
       "       [8.59231412e-01],\n",
       "       [3.85345906e-01],\n",
       "       [1.01015635e-01],\n",
       "       [1.59535352e-02],\n",
       "       [9.36105788e-01],\n",
       "       [7.61886388e-02],\n",
       "       [8.31346691e-01],\n",
       "       [1.01353697e-01],\n",
       "       [7.56426305e-02],\n",
       "       [7.96752572e-01],\n",
       "       [1.17367551e-01],\n",
       "       [9.38138843e-01],\n",
       "       [3.29484016e-01],\n",
       "       [2.27297544e-01],\n",
       "       [3.98242861e-01],\n",
       "       [9.80587378e-02],\n",
       "       [2.15128567e-02],\n",
       "       [7.58518815e-01],\n",
       "       [6.07620180e-01],\n",
       "       [7.59350955e-01],\n",
       "       [9.25240278e-01],\n",
       "       [4.62136537e-01],\n",
       "       [1.00366868e-01],\n",
       "       [9.00938451e-01],\n",
       "       [1.02964781e-01],\n",
       "       [1.00366868e-01],\n",
       "       [1.57380909e-01]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpred = model.predict(testdf)\n",
    "testpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to submit the result\n",
    "# add the passengerid and survived columns to the testpred\n",
    "testdf1 = pd.read_csv('test.csv')\n",
    "testdf1['Survived'] = testpred\n",
    "testdf1[['PassengerId','Survived']].to_csv('submission1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 1s 10ms/step - loss: 0.7182 - accuracy: 0.6142 - val_loss: 0.5348 - val_accuracy: 0.7556\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.6904 - val_loss: 0.4927 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6929 - val_loss: 0.4967 - val_accuracy: 0.8000\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7541 - val_loss: 0.4408 - val_accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.7428 - val_loss: 0.4571 - val_accuracy: 0.7778\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5288 - accuracy: 0.7491 - val_loss: 0.6733 - val_accuracy: 0.6444\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5615 - accuracy: 0.7528 - val_loss: 0.4647 - val_accuracy: 0.8222\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7553 - val_loss: 0.5566 - val_accuracy: 0.7111\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.7104 - val_loss: 0.4818 - val_accuracy: 0.8222\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5320 - accuracy: 0.7790 - val_loss: 0.4851 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8015 - val_loss: 0.4338 - val_accuracy: 0.8000\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7603 - val_loss: 0.4615 - val_accuracy: 0.8222\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.8015 - val_loss: 0.4486 - val_accuracy: 0.8111\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7990 - val_loss: 0.4437 - val_accuracy: 0.8000\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7940 - val_loss: 0.4369 - val_accuracy: 0.8111\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8015 - val_loss: 0.4584 - val_accuracy: 0.7889\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7803 - val_loss: 0.4445 - val_accuracy: 0.7889\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.8052 - val_loss: 0.4056 - val_accuracy: 0.7889\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7890 - val_loss: 0.4588 - val_accuracy: 0.7889\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7915 - val_loss: 0.4341 - val_accuracy: 0.8222\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7890 - val_loss: 0.4148 - val_accuracy: 0.8111\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8065 - val_loss: 0.4246 - val_accuracy: 0.8000\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8115 - val_loss: 0.4000 - val_accuracy: 0.8111\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7953 - val_loss: 0.4360 - val_accuracy: 0.8111\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.8115 - val_loss: 0.5071 - val_accuracy: 0.7444\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7878 - val_loss: 0.4270 - val_accuracy: 0.8111\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7940 - val_loss: 0.3990 - val_accuracy: 0.7889\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.8090 - val_loss: 0.3994 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7840 - val_loss: 0.4054 - val_accuracy: 0.8222\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8015 - val_loss: 0.4158 - val_accuracy: 0.8000\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8002 - val_loss: 0.5031 - val_accuracy: 0.7222\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5920 - accuracy: 0.7116 - val_loss: 0.4726 - val_accuracy: 0.8000\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7528 - val_loss: 0.4676 - val_accuracy: 0.7889\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5036 - accuracy: 0.7715 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7803 - val_loss: 0.4389 - val_accuracy: 0.8222\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7953 - val_loss: 0.3893 - val_accuracy: 0.7889\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.8015 - val_loss: 0.4839 - val_accuracy: 0.7667\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7828 - val_loss: 0.4033 - val_accuracy: 0.8222\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7890 - val_loss: 0.3842 - val_accuracy: 0.8222\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8002 - val_loss: 0.3966 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.8177 - val_loss: 0.3802 - val_accuracy: 0.8222\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7965 - val_loss: 0.4282 - val_accuracy: 0.8000\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7978 - val_loss: 0.3905 - val_accuracy: 0.8111\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8177 - val_loss: 0.3864 - val_accuracy: 0.8000\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8115 - val_loss: 0.3873 - val_accuracy: 0.8000\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.8140 - val_loss: 0.3858 - val_accuracy: 0.8000\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8127 - val_loss: 0.4396 - val_accuracy: 0.7778\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8040 - val_loss: 0.3991 - val_accuracy: 0.8111\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8127 - val_loss: 0.3958 - val_accuracy: 0.8000\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8052 - val_loss: 0.4009 - val_accuracy: 0.8000\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8040 - val_loss: 0.3883 - val_accuracy: 0.8000\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.8027 - val_loss: 0.3913 - val_accuracy: 0.8000\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8115 - val_loss: 0.3884 - val_accuracy: 0.8000\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4192 - accuracy: 0.8127 - val_loss: 0.3998 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.7990 - val_loss: 0.4155 - val_accuracy: 0.8111\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7978 - val_loss: 0.4108 - val_accuracy: 0.8111\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8127 - val_loss: 0.3887 - val_accuracy: 0.8111\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8115 - val_loss: 0.3871 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8115 - val_loss: 0.3963 - val_accuracy: 0.8000\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4119 - accuracy: 0.8202 - val_loss: 0.3767 - val_accuracy: 0.8000\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8090 - val_loss: 0.3890 - val_accuracy: 0.8222\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8202 - val_loss: 0.3815 - val_accuracy: 0.8000\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4105 - accuracy: 0.8215 - val_loss: 0.3943 - val_accuracy: 0.8000\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7915 - val_loss: 0.3868 - val_accuracy: 0.8222\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8190 - val_loss: 0.3747 - val_accuracy: 0.8222\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4025 - accuracy: 0.8077 - val_loss: 0.4052 - val_accuracy: 0.8111\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.8027 - val_loss: 0.3949 - val_accuracy: 0.8000\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8152 - val_loss: 0.3707 - val_accuracy: 0.8222\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8090 - val_loss: 0.3889 - val_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8202 - val_loss: 0.3750 - val_accuracy: 0.8000\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4127 - accuracy: 0.8140 - val_loss: 0.3858 - val_accuracy: 0.7889\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8140 - val_loss: 0.3771 - val_accuracy: 0.8222\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8002 - val_loss: 0.4053 - val_accuracy: 0.8222\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4146 - accuracy: 0.8040 - val_loss: 0.3677 - val_accuracy: 0.7778\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.3761 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8127 - val_loss: 0.3868 - val_accuracy: 0.7889\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8127 - val_loss: 0.3811 - val_accuracy: 0.7889\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.8152 - val_loss: 0.3958 - val_accuracy: 0.8000\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8165 - val_loss: 0.4932 - val_accuracy: 0.7778\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8102 - val_loss: 0.3936 - val_accuracy: 0.8111\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4051 - accuracy: 0.8052 - val_loss: 0.3988 - val_accuracy: 0.8111\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3910 - accuracy: 0.8252 - val_loss: 0.3799 - val_accuracy: 0.7889\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3906 - accuracy: 0.8290 - val_loss: 0.3980 - val_accuracy: 0.7889\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8252 - val_loss: 0.3934 - val_accuracy: 0.8000\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8265 - val_loss: 0.3925 - val_accuracy: 0.7889\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3843 - accuracy: 0.8252 - val_loss: 0.3751 - val_accuracy: 0.8222\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3950 - accuracy: 0.8202 - val_loss: 0.3785 - val_accuracy: 0.8222\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3873 - accuracy: 0.8290 - val_loss: 0.3734 - val_accuracy: 0.8111\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8315 - val_loss: 0.3910 - val_accuracy: 0.8111\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.8365 - val_loss: 0.3842 - val_accuracy: 0.8111\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4174 - accuracy: 0.8315 - val_loss: 0.4349 - val_accuracy: 0.8111\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.8090 - val_loss: 0.3956 - val_accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8265 - val_loss: 0.3709 - val_accuracy: 0.8222\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8302 - val_loss: 0.3858 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3789 - accuracy: 0.8352 - val_loss: 0.3833 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8140 - val_loss: 0.4003 - val_accuracy: 0.8111\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3895 - accuracy: 0.8377 - val_loss: 0.3798 - val_accuracy: 0.7889\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3812 - accuracy: 0.8315 - val_loss: 0.4095 - val_accuracy: 0.8111\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4058 - accuracy: 0.8152 - val_loss: 0.3922 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8302 - val_loss: 0.3799 - val_accuracy: 0.8111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ea6376bf0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# now we can use neural networks to predict the result\n",
    "# we can use keras to build the model\n",
    "# we can use sequential model\n",
    "# we can use dense layers\n",
    "# we can use dropout layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(255,activation='relu',input_shape=(X.shape[1],)))\n",
    "model.add(Dense(127,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(255,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Dense(63,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "lossf = tf.keras.losses.BinaryCrossentropy()\n",
    "early_stopping = EarlyStopping(min_delta=0.001, patience=10, restore_best_weights=True)\n",
    "model.compile(optimizer='adam',loss=lossf,metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "model.fit(X,y,epochs=100,batch_size=32,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert prediction to 0 and 1\n",
    "testpred = model.predict(testdf)\n",
    "testpred = np.where(testpred>0.5,1,0)\n",
    "testpred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make the submission file\n",
    "testdf1 = pd.read_csv('test.csv')\n",
    "testdf1['Survived'] = testpred\n",
    "testdf1[['PassengerId','Survived']].to_csv('submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    264\n",
      "1    154\n",
      "Name: Survived, dtype: int64\n",
      "0    275\n",
      "1    143\n",
      "Name: Survived, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    296\n",
       "1    122\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the results of both submission files\n",
    "sub1 = pd.read_csv('submission3.csv')\n",
    "sub2 = pd.read_csv('submission2.csv') \n",
    "sub3 = pd.read_csv('submission.csv')\n",
    "print(sub1['Survived'].value_counts())\n",
    "print(sub3['Survived'].value_counts())\n",
    "sub2['Survived'].value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2ed1c1e3dda2d1d09010f3df351d528d97a393444344645f0fddd23da56b409"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
